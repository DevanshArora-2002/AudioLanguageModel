# AudioLanguageModel
## Introduction
The 'Audio Language Models Problem' (ALMP) is a challenging machine learning project focused on developing and improving models to understand and generate human language from audio data. These models aim to process, comprehend and generate speech from diverse languages, dialects, and tones, potentially opening up numerous applications in fields such as voice assistants, automatic transcription services, and many others.
## Data
The major modeling was performed on Librispeech data(available at PyTorch) and Emotion/Event data is available at Kaggle 
https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio
https://www.kaggle.com/code/hidehisaarai1213/introduction-to-sound-event-detection
## Pre-requisites
All the necessary pre-requisites necessary to run the model have been mentioned in requirements.txt other than for Training_pengi the code has been borrowed from the following repository
https://github.com/RetroCirce/HTS-Audio-Transformer/tree/main
